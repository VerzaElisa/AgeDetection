{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3759a0bb-6414-4878-aa54-2c914dd66df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 15:46:15.350634: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 15:46:15.352891: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-31 15:46:15.380317: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 15:46:15.380378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 15:46:15.380396: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 15:46:15.386560: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-31 15:46:15.387409: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 15:46:16.880989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLIENTS = 10\n",
    "ACTIVE_CLIENTS = 5\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3530df22-440e-4ca2-8cf2-d317c2f03ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "df = pd.read_csv('emnist-letters.csv')\n",
    "train_df, test_df = train_test_split(df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "# Funzione per il preprocessing dei dati del singolo client con i pixel disposti in una matrice\n",
    "# 28x28 e normalizzati in un range [0,1], il dataset viene restitutito diviso in batch\n",
    "def preprocess(dataset):\n",
    "  def batch_format_fn(element):\n",
    "      return (tf.reshape(element['pixels'], [-1, 28, 28, 1]),\n",
    "              tf.reshape(element['label'], [-1, 1]))\n",
    "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
    "\n",
    "# Funzione per la creazione di un dataset ClientData a partire dal dataset di training a cui viene\n",
    "# aggiunta una colonna client_nums che assegna ad ogni riga un client randomico\n",
    "def create_clients(dataset):\n",
    "    # Viene creata una lista randomica di client\n",
    "    client_nums = list(range(NUM_CLIENTS))\n",
    "    generator = np.random.default_rng(42)\n",
    "    clients = generator.choice(client_nums, len(dataset))\n",
    "    dataset['client_nums'] = clients\n",
    "\n",
    "    # Viene convertito il dataset in una serie di dizionari, uno per ogni client, con label e pixel associati\n",
    "    client_train_dataset = collections.OrderedDict()\n",
    "    grouped_dataset = dataset.groupby('client_nums')\n",
    "    for key, item in grouped_dataset:\n",
    "        current_client = grouped_dataset.get_group(key)\n",
    "        data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
    "        client_train_dataset[key] = data\n",
    "\n",
    "    # I dizionari vengono convertiti in ClientDataset\n",
    "    def serializable_dataset_fn(client_id):\n",
    "        client_data = client_train_dataset[client_id]\n",
    "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
    "\n",
    "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=list(client_train_dataset.keys()),\n",
    "        serializable_dataset_fn=serializable_dataset_fn\n",
    "    )\n",
    "    \n",
    "    return tff_train_data\n",
    "    \n",
    "# Creazione della lista contenente i client con i relativi dataset\n",
    "train_df = create_clients(train_df)\n",
    "client_ids = sorted(train_df.client_ids)[:ACTIVE_CLIENTS]\n",
    "federated_train_data = [preprocess(train_df.create_tf_dataset_for_client(x)) for x in client_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65f86e8-a106-46d9-870d-128b741b3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per la creazione di un dataset ClientData a partire dal dataset di test\n",
    "def create_clients(dataset):\n",
    "    # Viene convertito il dataset in un dizionario con label e pixel\n",
    "    data = collections.OrderedDict((('label', dataset.iloc[:,0]), ('pixels', dataset.iloc[:,1:-1])))\n",
    "    # Il dizionario viene convertito in ClientDataset\n",
    "    def serializable_dataset_fn(client_ids):\n",
    "        return tf.data.Dataset.from_tensor_slices(data)\n",
    "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(client_ids=[0], serializable_dataset_fn=serializable_dataset_fn)\n",
    "    \n",
    "    return tff_train_data\n",
    "\n",
    "# Creazione del dataset di test\n",
    "central_test_df = create_clients(test_df)\n",
    "central_test_df = preprocess(central_test_df.create_tf_dataset_from_all_clients())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d704b0f-1751-441f-885d-42a218de2341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 15:46:50.588758: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "# Creazione del modello con le API di Keras\n",
    "def create_keras_model():\n",
    "  return keras.models.Sequential([keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='tanh', input_shape=(28, 28, 1), kernel_initializer=\"glorot_normal\"),\n",
    "                                  keras.layers.Dropout(rate=0.3),\n",
    "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "                                  keras.layers.Conv2D(filters=48, kernel_size=(5,5), activation='tanh'),\n",
    "                                  keras.layers.Dropout(rate=0.4),\n",
    "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "                                  keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='tanh'),\n",
    "                                  keras.layers.Flatten(),\n",
    "                                  keras.layers.Dense(120, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                                  keras.layers.Dense(84, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                                  keras.layers.Dense(26, activation='softmax')\n",
    "                                ])\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "# Creazione del modello TFF a partire dal modello Keras\n",
    "tff_model = tff.learning.models.functional_model_from_keras(keras_model,\n",
    "                                                            loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                                                            input_spec=federated_train_data[0].element_spec,\n",
    "                                                            metrics_constructor=collections.OrderedDict(accuracy=tf.keras.metrics.SparseCategoricalAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d25b236-0bca-4fe4-b6bf-fd2137432162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al client update si pu√≤ aggiungere un parametro che indica il numero di epoche in cui ripetere l'addestramento prima di inviare i pesi al server\n",
    "@tf.function\n",
    "def client_update(model, dataset, initial_weights, client_optimizer):\n",
    "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
    "  # Initialize the client model with the current server weights and the optimizer\n",
    "  # state.\n",
    "  client_weights = initial_weights.trainable\n",
    "  optimizer_state = client_optimizer.initialize(\n",
    "      tf.nest.map_structure(tf.TensorSpec.from_tensor, client_weights)\n",
    "  )\n",
    "\n",
    "  # Use the client_optimizer to update the local model.\n",
    "  for batch in dataset:\n",
    "    x, y = batch\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(client_weights)\n",
    "      # Compute a forward pass on the batch of data\n",
    "      outputs = model.predict_on_batch(\n",
    "          model_weights=(client_weights, ()), x=x, training=True\n",
    "      )\n",
    "      loss = model.loss(output=outputs, label=y)\n",
    "\n",
    "    # Compute the corresponding gradient\n",
    "    grads = tape.gradient(loss, client_weights)\n",
    "\n",
    "    # Apply the gradient using a client optimizer.\n",
    "    optimizer_state, client_weights = client_optimizer.next(\n",
    "        optimizer_state, weights=client_weights, gradients=grads\n",
    "    )\n",
    "\n",
    "  return tff.learning.models.ModelWeights(client_weights, non_trainable=())\n",
    "\n",
    "@tf.function\n",
    "def server_update(model, mean_client_weights):\n",
    "  return mean_client_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb91832b-610d-4e4e-a9f3-98c66ddca9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# La logica computazionale di tensorflow federated dev'essere separata rispetto alla logica\n",
    "# computazionale di tensorflow, qui vengono definite le funzioni di inizializzazione del server\n",
    "# e di aggiornamento dei client e del server\n",
    "\n",
    "# Inizializzazione del server con i pesi iniziali del modello\n",
    "@tff.tensorflow.computation\n",
    "def server_init():\n",
    "  return tff.learning.models.ModelWeights(*tff_model.initial_weights)\n",
    "\n",
    "# Vengono salvati i tipi di dato dei pesi del modello e del dataset    \n",
    "model_weights_type = server_init.type_signature.result\n",
    "tf_dataset_type = tff.SequenceType(tff.types.tensorflow_to_type(tff_model.input_spec))\n",
    "\n",
    "# Funzione di aggiornamento del client, viene passato il dataset del client edi pesi\n",
    "# aggiornati dal server, restituisce i pesi aggiornati del client\n",
    "@tff.tensorflow.computation(tf_dataset_type, model_weights_type)\n",
    "def client_update_fn(tf_dataset, server_weights):\n",
    "  client_optimizer = tff.learning.optimizers.build_adam(learning_rate=0.01)\n",
    "  return client_update(tff_model, tf_dataset, server_weights, client_optimizer)\n",
    "\n",
    "# Funzione di aggiornamento del server, riceve i pesi mediati dai client e restituisce\n",
    "# i pesi aggiornati del server\n",
    "@tff.tensorflow.computation(model_weights_type)\n",
    "def server_update_fn(mean_client_weights):\n",
    "  return server_update(tff_model, mean_client_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc49222d-2f06-44ad-bcde-7b45679d2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiornati i tipi di dato dei pesi del modello e del dataset con i tipi federati\n",
    "# includendo oltre al tipo di dato il placement\n",
    "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
    "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)\n",
    "\n",
    "# Definizione della computazione federata per l'inizializzazione del server\n",
    "# la funzione ritorna i pesi iniziali del modello\n",
    "@tff.federated_computation\n",
    "def initialize_fn():\n",
    "  return tff.federated_eval(server_init, tff.SERVER)\n",
    "\n",
    "# Definizione della computazione federata per un round di training. Si divide in 3 parti:\n",
    "# 1. Broadcast dei pesi del server ai client\n",
    "# 2. Chiamata della funzione di aggiornamento del client\n",
    "# 3. Il server aggiorna i pesi facendo la media dei pesi dei client\n",
    "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
    "def next_fn(server_weights, federated_dataset):  \n",
    "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
    "  client_weights = tff.federated_map(client_update_fn, (federated_dataset, server_weights_at_client))\n",
    "  server_weights = tff.federated_map(server_update_fn, tff.federated_mean(client_weights))\n",
    "\n",
    "  return server_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45946e2-dfab-40e5-b03c-5222ff0721c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model_weights):\n",
    "  keras_model = create_keras_model()\n",
    "  keras_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "  )\n",
    "  model_weights.assign_weights_to(keras_model)\n",
    "  keras_model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2953253e-27d4-45de-8f4d-14516409eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 15:49:50.750099: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:50.750339: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.076886: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.077111: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.182531: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.182875: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.196195: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.196494: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.210883: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.211059: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.224995: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.225163: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.244794: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.244983: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.268347: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.268503: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.292216: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.292395: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:53.311233: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 15:49:53.311433: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 15:49:55.354047: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n",
      "\t [[{{node conv2d_3_input}}]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2024-07-31 15:49:55.436662: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n",
      "\t [[{{node conv2d_3_input}}]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2024-07-31 15:49:55.451981: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n",
      "\t [[{{node conv2d_3_input}}]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2024-07-31 15:49:55.454843: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n",
      "\t [[{{node conv2d_3_input}}]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2024-07-31 15:49:55.455265: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n",
      "\t [[{{node conv2d_3_input}}]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n\t [[{{node conv2d_3_input}}]]\n\t [[StatefulPartitionedCall]]\n\t [[StatefulPartitionedCall]]\n\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_jvu22] in block locals [_jvu1,_jvu2,_jvu3,_jvu14,_jvu15,_jvu16,_jvu17,_jvu18,_jvu19,_jvu20,_jvu21,_jvu22,_jvu23,_jvu24]\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-07-31T15:49:55.456998826+00:00\", grpc_status:13, grpc_message:\"Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor \\'conv2d_3_input\\' with dtype float and shape [?,28,28,1]\\n\\t [[{{node conv2d_3_input}}]]\\n\\t [[StatefulPartitionedCall]]\\n\\t [[StatefulPartitionedCall]]\\n\\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_jvu22] in block locals [_jvu1,_jvu2,_jvu3,_jvu14,_jvu15,_jvu16,_jvu17,_jvu18,_jvu19,_jvu20,_jvu21,_jvu22,_jvu23,_jvu24]\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Addestramento distribuito del modello\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m   server_state \u001b[38;5;241m=\u001b[39m \u001b[43mfederated_algorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_train_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m   evaluate(server_state)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:151\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    146\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\n\u001b[1;32m    147\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter,  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    148\u001b[0m       args,\n\u001b[1;32m    149\u001b[0m       kwargs,\n\u001b[1;32m    150\u001b[0m   )\n\u001b[0;32m--> 151\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_result(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:65\u001b[0m, in \u001b[0;36mSyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 65\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/common_libs/async_utils.py:66\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/common_libs/retrying.py:119\u001b[0m, in \u001b[0;36mretry.<locals>.retry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    118\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m retry_on_exception_filter(e):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    120\u001b[0m   retry_wait_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(wait_max_ms, retry_wait_ms \u001b[38;5;241m*\u001b[39m wait_multiplier)\n\u001b[1;32m    121\u001b[0m   \u001b[38;5;66;03m# asyncio.sleep takes arguments in seconds.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/common_libs/retrying.py:109\u001b[0m, in \u001b[0;36mretry.<locals>.retry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_on_result_filter(result):\n\u001b[1;32m    111\u001b[0m       retry_wait_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(wait_max_ms, retry_wait_ms \u001b[38;5;241m*\u001b[39m wait_multiplier)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py:229\u001b[0m, in \u001b[0;36mAsyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m   arg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tracing\u001b[38;5;241m.\u001b[39mwrap_coroutine_in_current_trace_context(\n\u001b[1;32m    226\u001b[0m       _ingest(executor, arg, comp\u001b[38;5;241m.\u001b[39mtype_signature\u001b[38;5;241m.\u001b[39mparameter)\n\u001b[1;32m    227\u001b[0m   )\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m tracing\u001b[38;5;241m.\u001b[39mwrap_coroutine_in_current_trace_context(\n\u001b[1;32m    230\u001b[0m     _invoke(executor, comp, arg, result_type)\n\u001b[1;32m    231\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/common_libs/tracing.py:406\u001b[0m, in \u001b[0;36mwrap_coroutine_in_current_trace_context.<locals>._wrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped\u001b[39m():\n\u001b[1;32m    405\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _with_span_yields(trace_span_yields):\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py:132\u001b[0m, in \u001b[0;36m_invoke\u001b[0;34m(executor, comp, arg, result_type)\u001b[0m\n\u001b[1;32m    130\u001b[0m   py_typecheck\u001b[38;5;241m.\u001b[39mcheck_type(arg, executor_value_base\u001b[38;5;241m.\u001b[39mExecutorValue)\n\u001b[1;32m    131\u001b[0m comp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mcreate_value(comp, comp\u001b[38;5;241m.\u001b[39mtype_signature)\n\u001b[0;32m--> 132\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mcreate_call(comp, arg)\n\u001b[1;32m    133\u001b[0m py_typecheck\u001b[38;5;241m.\u001b[39mcheck_type(result, executor_value_base\u001b[38;5;241m.\u001b[39mExecutorValue)\n\u001b[1;32m    134\u001b[0m result_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/common_libs/tracing.py:207\u001b[0m, in \u001b[0;36mtrace.<locals>.async_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Run the underlying function, recording the resulting value or exception\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# and passing it back to the span generator\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[1;32m    208\u001b[0m   completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor.py:250\u001b[0m, in \u001b[0;36mRemoteExecutor.create_call\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    244\u001b[0m   py_typecheck\u001b[38;5;241m.\u001b[39mcheck_type(arg, RemoteValue)\n\u001b[1;32m    245\u001b[0m create_call_request \u001b[38;5;241m=\u001b[39m executor_pb2\u001b[38;5;241m.\u001b[39mCreateCallRequest(\n\u001b[1;32m    246\u001b[0m     executor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_id,\n\u001b[1;32m    247\u001b[0m     function_ref\u001b[38;5;241m=\u001b[39mcomp\u001b[38;5;241m.\u001b[39mreference,\n\u001b[1;32m    248\u001b[0m     argument_ref\u001b[38;5;241m=\u001b[39m(arg\u001b[38;5;241m.\u001b[39mreference \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    249\u001b[0m )\n\u001b[0;32m--> 250\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_call_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m py_typecheck\u001b[38;5;241m.\u001b[39mcheck_type(response, executor_pb2\u001b[38;5;241m.\u001b[39mCreateCallResponse)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RemoteValue(response\u001b[38;5;241m.\u001b[39mvalue_ref, comp\u001b[38;5;241m.\u001b[39mtype_signature\u001b[38;5;241m.\u001b[39mresult, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:87\u001b[0m, in \u001b[0;36mRemoteExecutorGrpcStub.create_call\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_call\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m, request: executor_pb2\u001b[38;5;241m.\u001b[39mCreateCallRequest\n\u001b[1;32m     85\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m executor_pb2\u001b[38;5;241m.\u001b[39mCreateCallResponse:\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Dispatches a CreateCall gRPC.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateCall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/common_libs/tracing.py:236\u001b[0m, in \u001b[0;36mtrace.<locals>.sync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m   completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    238\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:40\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(rpc_func, request)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m executors_errors\u001b[38;5;241m.\u001b[39mRetryableGRPCError(e)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:31\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(rpc_func, request)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing\u001b[38;5;241m.\u001b[39mwrap_rpc_in_trace_context():\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrpc_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, grpc\u001b[38;5;241m.\u001b[39mCall)\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode() \u001b[38;5;129;01min\u001b[39;00m executors_errors\u001b[38;5;241m.\u001b[39mget_grpc_retryable_error_codes()\n\u001b[1;32m     36\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[1;32m   1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m     )\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m state\u001b[38;5;241m.\u001b[39mresponse\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\n\t [[{{node conv2d_3_input}}]]\n\t [[StatefulPartitionedCall]]\n\t [[StatefulPartitionedCall]]\n\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_jvu22] in block locals [_jvu1,_jvu2,_jvu3,_jvu14,_jvu15,_jvu16,_jvu17,_jvu18,_jvu19,_jvu20,_jvu21,_jvu22,_jvu23,_jvu24]\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-07-31T15:49:55.456998826+00:00\", grpc_status:13, grpc_message:\"Failed to run computation: {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1174}} {{function_node __forward_predict_on_batch_1100}} {{function_node __forward_predict_on_batch_1100}} You must feed a value for placeholder tensor \\'conv2d_3_input\\' with dtype float and shape [?,28,28,1]\\n\\t [[{{node conv2d_3_input}}]]\\n\\t [[StatefulPartitionedCall]]\\n\\t [[StatefulPartitionedCall]]\\n\\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_jvu22] in block locals [_jvu1,_jvu2,_jvu3,_jvu14,_jvu15,_jvu16,_jvu17,_jvu18,_jvu19,_jvu20,_jvu21,_jvu22,_jvu23,_jvu24]\"}\"\n>"
     ]
    }
   ],
   "source": [
    "# Viene creato l'iterative process con le funzioni init e next custom\n",
    "federated_algorithm = tff.templates.IterativeProcess(initialize_fn=initialize_fn, next_fn=next_fn)\n",
    "\n",
    "# Inizializzazione del server\n",
    "server_state = federated_algorithm.initialize()\n",
    "\n",
    "# Addestramento distribuito del modello\n",
    "for _ in range(15):\n",
    "  server_state = federated_algorithm.next(server_state, federated_train_data)\n",
    "  evaluate(server_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c52ca-aef5-4d92-bbb9-f7a0ee6b64a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
