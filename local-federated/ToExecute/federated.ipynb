{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3759a0bb-6414-4878-aa54-2c914dd66df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tensorflow_federated\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLIENTS = 10\n",
    "ACTIVE_CLIENTS = 4\n",
    "BATCH_SIZE = 20\n",
    "path = os.path.dirname(tff.__file__)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8297d26f-e0bf-480b-9c3f-4c7df497b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "df = pd.read_csv('emnist-letters.csv')\n",
    "train_df, test_df = train_test_split(df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "# Funzione per il preprocessiSng dei dati del singolo client con i pixel disposti in una matrice\n",
    "# 28x28 il dataset viene restitutito diviso in batch\n",
    "def preprocess(dataset):\n",
    "  def batch_format_fn(element):\n",
    "      return (tf.reshape(float(element['pixels']/255), [-1, 28, 28, 1]),\n",
    "              tf.reshape(element['label'], [-1, 1]))\n",
    "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3530df22-440e-4ca2-8cf2-d317c2f03ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per la creazione di un dataset ClientData a partire dal dataset di training a cui viene\n",
    "# aggiunta una colonna client_nums che assegna ad ogni riga un client randomico\n",
    "def create_clients(dataset):\n",
    "    # Viene creata una lista randomica di client\n",
    "    client_nums = list(range(NUM_CLIENTS))\n",
    "    generator = np.random.default_rng(42)\n",
    "    clients = generator.choice(client_nums, len(dataset))\n",
    "    dataset['client_nums'] = clients\n",
    "\n",
    "    # Viene convertito il dataset in dizionari, uno per ogni client, con label e pixel associati\n",
    "    client_train_dataset = collections.OrderedDict()\n",
    "    grouped_dataset = dataset.groupby('client_nums')\n",
    "    for key, item in grouped_dataset:\n",
    "        current_client = grouped_dataset.get_group(key)\n",
    "        data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
    "        client_train_dataset[key] = data\n",
    "\n",
    "    # I dizionari vengono convertiti in ClientDataset\n",
    "    def serializable_dataset_fn(client_id):\n",
    "        client_data = client_train_dataset[client_id]\n",
    "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
    "\n",
    "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=list(client_train_dataset.keys()),\n",
    "        serializable_dataset_fn=serializable_dataset_fn\n",
    "    )\n",
    "    \n",
    "    return tff_train_data\n",
    "\n",
    "# Funzione per la creazione di un dataset ClientData a partire dal dataset di test\n",
    "# Il test è centralizzato, quindi viene impostato un client fittizio a zero\n",
    "def create_test(dataset):\n",
    "    zeros = [0]*len(dataset)\n",
    "    dataset['client_nums'] = zeros\n",
    "    \n",
    "    # Viene convertito il dataset in un dizionario\n",
    "    client_train_dataset = collections.OrderedDict()\n",
    "    grouped_dataset = dataset.groupby('client_nums')\n",
    "    current_client = grouped_dataset.get_group(0)\n",
    "    data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
    "    client_train_dataset[0] = data\n",
    "\n",
    "    # Il dizionario viene convertito in ClientDataset\n",
    "    def serializable_dataset_fn(client_id = 0):\n",
    "        client_data = client_train_dataset[0]\n",
    "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
    "\n",
    "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=[0],\n",
    "        serializable_dataset_fn=serializable_dataset_fn\n",
    "    )\n",
    "    \n",
    "    return tff_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f65f86e8-a106-46d9-870d-128b741b3b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creazione della lista contenente i client con i relativi dataset\n",
    "client_data_df = create_clients(train_df)\n",
    "client_ids = sorted(client_data_df.client_ids)[:ACTIVE_CLIENTS]\n",
    "federated_train_data = [preprocess(client_data_df.create_tf_dataset_for_client(x)) for x in client_ids]\n",
    "\n",
    "# Creazione del dataset di test\n",
    "central_test_df = create_test(test_df)\n",
    "central_test_df = preprocess(central_test_df.create_tf_dataset_for_client(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd3779-9d9f-4b49-9a2f-783456deccc5",
   "metadata": {},
   "source": [
    "La struttura del train è la seguente:\n",
    "    * federated_train_data ha un entry per client\n",
    "    * Ogni client ha un certo numero di batch\n",
    "    * Ogni batch è un array con due elementi, uno contiene tutti i pixel, l'altro tutte le label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854923f9-5956-4a3f-a91f-4666f495a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di clients: 10\n",
      "Numero di batch per client 0: 353\n",
      "Numero elementi per client: 7042\n",
      "Numero di batch per client 1: 359\n",
      "Numero elementi per client: 7167\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m client_data_df\u001b[38;5;241m.\u001b[39mclient_ids:\n\u001b[1;32m      6\u001b[0m     num_elem \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfederated_train_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      8\u001b[0m         num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(i[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      9\u001b[0m         num_elem \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Controlli consistenza datast vs. DataClient\n",
    "\n",
    "print('Numero di clients: '+str(len(client_data_df.client_ids)))\n",
    "total = 0\n",
    "for x in client_data_df.client_ids:\n",
    "    num_elem = 0\n",
    "    for i in federated_train_data[x]:\n",
    "        num = len(list(i[1]))\n",
    "        num_elem += num\n",
    "        total += num\n",
    "    print('Numero di batch per client {}: {}\\nNumero elementi per client: {}'.format(x, str(len(federated_train_data[x])), str(num_elem)))\n",
    "print('TOT TRAIN CD: {} \\nTOT TRAIN DF: {}'.format(total, train_df.shape))\n",
    "\n",
    "\n",
    "num_elem = 0\n",
    "for i in central_test_df:\n",
    "    num = len(list(i[1]))\n",
    "    num_elem += num\n",
    "print('Numero di batch per il test set: {}'.format(str(len(central_test_df))))\n",
    "print('TOT TEST CD: {} \\nTOT TEST DF: {}'.format(str(num_elem), test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0f994bd-57f2-47a8-a669-c936cebf5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello con le API di Keras\n",
    "def create_keras_model():\n",
    "  return keras.models.Sequential([keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='tanh', input_shape=(28, 28, 1), kernel_initializer=\"glorot_normal\"),\n",
    "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "                                  keras.layers.Conv2D(filters=48, kernel_size=(5,5), activation='tanh'),\n",
    "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "                                  keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='tanh'),\n",
    "                                  keras.layers.Flatten(),\n",
    "                                  keras.layers.Dense(120, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                                  keras.layers.Dense(84, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                                  keras.layers.Dense(27, activation='softmax')\n",
    "                                ])\n",
    "keras_model = create_keras_model()\n",
    "# Creazione del modello TFF a partire dal modello Keras\n",
    "tff_model = tff.learning.models.functional_model_from_keras(keras_model,\n",
    "                                                            loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                                                            input_spec=federated_train_data[0].element_spec,\n",
    "                                                            metrics_constructor=collections.OrderedDict(accuracy=tf.keras.metrics.SparseCategoricalAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d25b236-0bca-4fe4-b6bf-fd2137432162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al client update si può aggiungere un parametro che indica il numero di epoche in cui ripetere l'addestramento prima di inviare i pesi al server\n",
    "@tf.function\n",
    "def client_update(model, dataset, initial_weights, client_optimizer):\n",
    "\n",
    "  client_weights = initial_weights.trainable\n",
    "  optimizer_state = client_optimizer.initialize(tf.nest.map_structure(tf.TensorSpec.from_tensor, client_weights))\n",
    "  for _ in range(10):\n",
    "    for batch in dataset:\n",
    "      x, y = batch\n",
    "      with tf.GradientTape() as tape:\n",
    "        tape.watch(client_weights)\n",
    "        # Compute a forward pass on the batch of data\n",
    "        outputs = model.predict_on_batch(model_weights=(client_weights, ()), x=x, training=True)\n",
    "        loss = model.loss(output=outputs, label=y)\n",
    "\n",
    "      # Compute the corresponding gradient\n",
    "      grads = tape.gradient(loss, client_weights)\n",
    "\n",
    "      # Apply the gradient using a client optimizer.\n",
    "      optimizer_state, client_weights = client_optimizer.next(optimizer_state, weights=client_weights, gradients=grads)\n",
    "\n",
    "  return tff.learning.models.ModelWeights(client_weights, non_trainable=())\n",
    "\n",
    "@tf.function\n",
    "def server_update(model, mean_client_weights):\n",
    "  del model\n",
    "  return mean_client_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb91832b-610d-4e4e-a9f3-98c66ddca9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# La logica computazionale di tensorflow federated dev'essere separata rispetto alla logica\n",
    "# computazionale di tensorflow, qui vengono definite le funzioni di inizializzazione del server\n",
    "# e di aggiornamento dei client e del server\n",
    "\n",
    "# Inizializzazione del server con i pesi iniziali del modello\n",
    "@tff.tensorflow.computation\n",
    "def server_init():\n",
    "  return tff.learning.models.ModelWeights(*tff_model.initial_weights)\n",
    "\n",
    "# Vengono salvati i tipi di dato dei pesi del modello e del dataset    \n",
    "model_weights_type = server_init.type_signature.result\n",
    "tf_dataset_type = tff.SequenceType(tff.types.tensorflow_to_type(tff_model.input_spec))\n",
    "\n",
    "# Funzione di aggiornamento del client, viene passato il dataset del client edi pesi\n",
    "# aggiornati dal server, restituisce i pesi aggiornati del client\n",
    "@tff.tensorflow.computation(tf_dataset_type, model_weights_type)\n",
    "def client_update_fn(tf_dataset, server_weights):\n",
    "  client_optimizer = tff.learning.optimizers.build_adam(learning_rate=0.01)\n",
    "  return client_update(tff_model, tf_dataset, server_weights, client_optimizer)\n",
    "\n",
    "# Funzione di aggiornamento del server, riceve i pesi mediati dai client e restituisce\n",
    "# i pesi aggiornati del server\n",
    "@tff.tensorflow.computation(model_weights_type)\n",
    "def server_update_fn(mean_client_weights):\n",
    "  return server_update(tff_model, mean_client_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc49222d-2f06-44ad-bcde-7b45679d2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiornati i tipi di dato dei pesi del modello e del dataset con i tipi federati\n",
    "# includendo oltre al tipo di dato il placement\n",
    "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
    "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)\n",
    "\n",
    "# Definizione della computazione federata per l'inizializzazione del server\n",
    "# la funzione ritorna i pesi iniziali del modello\n",
    "@tff.federated_computation\n",
    "def initialize_fn():\n",
    "  return tff.federated_eval(server_init, tff.SERVER)\n",
    "\n",
    "# Definizione della computazione federata per un round di training. Si divide in 3 parti:\n",
    "# 1. Broadcast dei pesi del server ai client\n",
    "# 2. Chiamata della funzione di aggiornamento del client\n",
    "# 3. Il server aggiorna i pesi facendo la media dei pesi dei client\n",
    "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
    "def next_fn(server_weights, federated_dataset):  \n",
    "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
    "  client_weights = tff.federated_map(client_update_fn, (federated_dataset, server_weights_at_client))\n",
    "  server_weights = tff.federated_map(server_update_fn, tff.federated_mean(client_weights))\n",
    "\n",
    "  return server_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d45946e2-dfab-40e5-b03c-5222ff0721c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model_weights):\n",
    "  keras_model = create_keras_model()\n",
    "  keras_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "  )\n",
    "  model_weights.assign_weights_to(keras_model)\n",
    "  keras_model.evaluate(central_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2953253e-27d4-45de-8f4d-14516409eef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 16:47:18.342841: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:18.343361: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "# Viene creato l'iterative process con le funzioni init e next custom\n",
    "federated_algorithm = tff.templates.IterativeProcess(initialize_fn=initialize_fn, next_fn=next_fn)\n",
    "\n",
    "# Inizializzazione del server\n",
    "server_state = federated_algorithm.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b71ccb84-66c6-4553-9336-85d8001768e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre server state 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 16:47:18.680284: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:18.680664: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.005030: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.005386: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.022818: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.023134: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.046834: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.047067: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.061194: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.061370: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.080969: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.081195: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.117880: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.118089: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.150484: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.150684: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-08-07 16:47:19.185837: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-08-07 16:47:19.186200: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post server state 1\n",
      "pre server state 2\n",
      "post server state 2\n",
      "pre server state 3\n",
      "post server state 3\n",
      "pre server state 4\n",
      "post server state 4\n",
      "pre server state 5\n",
      "post server state 5\n",
      "888/888 [==============================] - 7s 7ms/step - loss: 10.5512 - sparse_categorical_accuracy: 0.0379\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for _ in range(5):\n",
    "    print('pre server state '+str(i))\n",
    "    server_state = federated_algorithm.next(server_state, federated_train_data)\n",
    "    print('post server state '+str(i))\n",
    "    i+=1\n",
    "evaluate(server_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69b7db-ee3d-4359-b397-95d4aac77956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
