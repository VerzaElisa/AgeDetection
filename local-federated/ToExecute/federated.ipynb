{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759a0bb-6414-4878-aa54-2c914dd66df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLIENTS = 2\n",
    "ACTIVE_CLIENTS = 2\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297d26f-e0bf-480b-9c3f-4c7df497b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "df = pd.read_csv('emnist-letters.csv')\n",
    "train_df, test_df = train_test_split(df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "# Funzione per il preprocessing dei dati del singolo client con i pixel disposti in una matrice\n",
    "# 28x28 il dataset viene restitutito diviso in batch\n",
    "def preprocess(dataset):\n",
    "  def batch_format_fn(element):\n",
    "      return (tf.reshape(float(element['pixels']/255), [-1, 28, 28, 1]),\n",
    "              tf.reshape(element['label'], [-1, 1]))\n",
    "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530df22-440e-4ca2-8cf2-d317c2f03ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per la creazione di un dataset ClientData a partire dal dataset di training a cui viene\n",
    "# aggiunta una colonna client_nums che assegna ad ogni riga un client randomico\n",
    "def create_clients(dataset):\n",
    "    # Viene creata una lista randomica di client\n",
    "    client_nums = list(range(NUM_CLIENTS))\n",
    "    generator = np.random.default_rng(42)\n",
    "    clients = generator.choice(client_nums, len(dataset))\n",
    "    dataset['client_nums'] = clients\n",
    "\n",
    "    # Viene convertito il dataset in dizionari, uno per ogni client, con label e pixel associati\n",
    "    client_train_dataset = collections.OrderedDict()\n",
    "    grouped_dataset = dataset.groupby('client_nums')\n",
    "    for key, item in grouped_dataset:\n",
    "        current_client = grouped_dataset.get_group(key)\n",
    "        data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
    "        client_train_dataset[key] = data\n",
    "\n",
    "    # I dizionari vengono convertiti in ClientDataset\n",
    "    def serializable_dataset_fn(client_id):\n",
    "        client_data = client_train_dataset[client_id]\n",
    "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
    "\n",
    "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=list(client_train_dataset.keys()),\n",
    "        serializable_dataset_fn=serializable_dataset_fn\n",
    "    )\n",
    "    \n",
    "    return tff_train_data\n",
    "\n",
    "# Funzione per la creazione di un dataset ClientData a partire dal dataset di test\n",
    "# Il test è centralizzato, quindi viene impostato un client fittizio a zero\n",
    "def create_test(dataset):\n",
    "    zeros = [0]*len(dataset)\n",
    "    dataset['client_nums'] = zeros\n",
    "    \n",
    "    # Viene convertito il dataset in un dizionario\n",
    "    client_train_dataset = collections.OrderedDict()\n",
    "    grouped_dataset = dataset.groupby('client_nums')\n",
    "    current_client = grouped_dataset.get_group(0)\n",
    "    data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
    "    client_train_dataset[0] = data\n",
    "\n",
    "    # Il dizionario viene convertito in ClientDataset\n",
    "    def serializable_dataset_fn(client_id = 0):\n",
    "        client_data = client_train_dataset[0]\n",
    "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
    "\n",
    "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=[0],\n",
    "        serializable_dataset_fn=serializable_dataset_fn\n",
    "    )\n",
    "    \n",
    "    return tff_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f86e8-a106-46d9-870d-128b741b3b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creazione della lista contenente i client con i relativi dataset\n",
    "client_data_df = create_clients(train_df)\n",
    "client_ids = sorted(client_data_df.client_ids)[:ACTIVE_CLIENTS]\n",
    "federated_train_data = [preprocess(client_data_df.create_tf_dataset_for_client(x)) for x in client_ids]\n",
    "\n",
    "# Creazione del dataset di test\n",
    "central_test_df = create_test(test_df)\n",
    "central_test_df = preprocess(central_test_df.create_tf_dataset_for_client(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd3779-9d9f-4b49-9a2f-783456deccc5",
   "metadata": {},
   "source": [
    "La struttura del train è la seguente:\n",
    "    * federated_train_data ha un entry per client\n",
    "    * Ogni client ha un certo numero di batch\n",
    "    * Ogni batch è un array con due elementi, uno contiene tutti i pixel, l'altro tutte le label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854923f9-5956-4a3f-a91f-4666f495a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlli consistenza datast vs. DataClient\n",
    "\n",
    "print('Numero di clients: '+str(len(client_data_df.client_ids)))\n",
    "total = 0\n",
    "for x in client_data_df.client_ids:\n",
    "    num_elem = 0\n",
    "    for i in federated_train_data[x]:\n",
    "        num = len(list(i[1]))\n",
    "        num_elem += num\n",
    "        total += num\n",
    "    print('Numero di batch per client {}: {}\\nNumero elementi per client: {}'.format(x, str(len(federated_train_data[x])), str(num_elem)))\n",
    "print('TOT TRAIN CD: {} \\nTOT TRAIN DF: {}'.format(total, train_df.shape))\n",
    "\n",
    "\n",
    "num_elem = 0\n",
    "for i in central_test_df:\n",
    "    num = len(list(i[1]))\n",
    "    num_elem += num\n",
    "print('Numero di batch per il test set: {}'.format(str(len(central_test_df))))\n",
    "print('TOT TEST CD: {} \\nTOT TEST DF: {}'.format(str(num_elem), test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f994bd-57f2-47a8-a669-c936cebf5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello con le API di Keras\n",
    "def create_keras_model():\n",
    "  return keras.models.Sequential([keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='tanh', input_shape=(28, 28, 1), kernel_initializer=\"glorot_normal\"),\n",
    "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "                                  keras.layers.Conv2D(filters=48, kernel_size=(5,5), activation='tanh'),\n",
    "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "                                  keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='tanh'),\n",
    "                                  keras.layers.Flatten(),\n",
    "                                  keras.layers.Dense(120, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                                  keras.layers.Dense(84, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                                  keras.layers.Dense(27, activation='softmax')\n",
    "                                ])\n",
    "keras_model = create_keras_model()\n",
    "# Creazione del modello TFF a partire dal modello Keras\n",
    "tff_model = tff.learning.models.functional_model_from_keras(keras_model,\n",
    "                                                            loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                                                            input_spec=federated_train_data[0].element_spec,\n",
    "                                                            metrics_constructor=collections.OrderedDict(accuracy=tf.keras.metrics.SparseCategoricalAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25b236-0bca-4fe4-b6bf-fd2137432162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al client update si può aggiungere un parametro che indica il numero di epoche in cui ripetere l'addestramento prima di inviare i pesi al server\n",
    "@tf.function\n",
    "def client_update(model, dataset, initial_weights, client_optimizer):\n",
    "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
    "  # Initialize the client model with the current server weights and the optimizer\n",
    "  # state.\n",
    "  client_weights = initial_weights.trainable\n",
    "  optimizer_state = client_optimizer.initialize(\n",
    "      tf.nest.map_structure(tf.TensorSpec.from_tensor, client_weights)\n",
    "  )\n",
    "\n",
    "  # Use the client_optimizer to update the local model.\n",
    "  for batch in dataset:\n",
    "    print(batch)\n",
    "    x, y = batch\n",
    "    print(x)\n",
    "    print(y)\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(client_weights)\n",
    "      # Compute a forward pass on the batch of data\n",
    "      outputs = model.predict_on_batch(\n",
    "          model_weights=(client_weights, ()), x=x, training=True\n",
    "      )\n",
    "      loss = model.loss(output=outputs, label=y)\n",
    "\n",
    "    # Compute the corresponding gradient\n",
    "    grads = tape.gradient(loss, client_weights)\n",
    "\n",
    "    # Apply the gradient using a client optimizer.\n",
    "    optimizer_state, client_weights = client_optimizer.next(\n",
    "        optimizer_state, weights=client_weights, gradients=grads\n",
    "    )\n",
    "\n",
    "  return tff.learning.models.ModelWeights(client_weights, non_trainable=())\n",
    "\n",
    "@tf.function\n",
    "def server_update(model, mean_client_weights):\n",
    "  return mean_client_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91832b-610d-4e4e-a9f3-98c66ddca9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# La logica computazionale di tensorflow federated dev'essere separata rispetto alla logica\n",
    "# computazionale di tensorflow, qui vengono definite le funzioni di inizializzazione del server\n",
    "# e di aggiornamento dei client e del server\n",
    "\n",
    "# Inizializzazione del server con i pesi iniziali del modello\n",
    "@tff.tensorflow.computation\n",
    "def server_init():\n",
    "  return tff.learning.models.ModelWeights(*tff_model.initial_weights)\n",
    "\n",
    "# Vengono salvati i tipi di dato dei pesi del modello e del dataset    \n",
    "model_weights_type = server_init.type_signature.result\n",
    "tf_dataset_type = tff.SequenceType(tff.types.tensorflow_to_type(tff_model.input_spec))\n",
    "\n",
    "# Funzione di aggiornamento del client, viene passato il dataset del client edi pesi\n",
    "# aggiornati dal server, restituisce i pesi aggiornati del client\n",
    "@tff.tensorflow.computation(tf_dataset_type, model_weights_type)\n",
    "def client_update_fn(tf_dataset, server_weights):\n",
    "  client_optimizer = tff.learning.optimizers.build_adam(learning_rate=0.01)\n",
    "  return client_update(tff_model, tf_dataset, server_weights, client_optimizer)\n",
    "\n",
    "# Funzione di aggiornamento del server, riceve i pesi mediati dai client e restituisce\n",
    "# i pesi aggiornati del server\n",
    "@tff.tensorflow.computation(model_weights_type)\n",
    "def server_update_fn(mean_client_weights):\n",
    "  return server_update(tff_model, mean_client_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49222d-2f06-44ad-bcde-7b45679d2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiornati i tipi di dato dei pesi del modello e del dataset con i tipi federati\n",
    "# includendo oltre al tipo di dato il placement\n",
    "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
    "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)\n",
    "\n",
    "# Definizione della computazione federata per l'inizializzazione del server\n",
    "# la funzione ritorna i pesi iniziali del modello\n",
    "@tff.federated_computation\n",
    "def initialize_fn():\n",
    "  return tff.federated_eval(server_init, tff.SERVER)\n",
    "\n",
    "# Definizione della computazione federata per un round di training. Si divide in 3 parti:\n",
    "# 1. Broadcast dei pesi del server ai client\n",
    "# 2. Chiamata della funzione di aggiornamento del client\n",
    "# 3. Il server aggiorna i pesi facendo la media dei pesi dei client\n",
    "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
    "def next_fn(server_weights, federated_dataset):  \n",
    "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
    "  client_weights = tff.federated_map(client_update_fn, (federated_dataset, server_weights_at_client))\n",
    "  server_weights = tff.federated_map(server_update_fn, tff.federated_mean(client_weights))\n",
    "\n",
    "  return server_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45946e2-dfab-40e5-b03c-5222ff0721c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model_weights):\n",
    "  keras_model = create_keras_model()\n",
    "  keras_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "  )\n",
    "  model_weights.assign_weights_to(keras_model)\n",
    "  keras_model.evaluate(central_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953253e-27d4-45de-8f4d-14516409eef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Viene creato l'iterative process con le funzioni init e next custom\n",
    "federated_algorithm = tff.templates.IterativeProcess(initialize_fn=initialize_fn, next_fn=next_fn)\n",
    "\n",
    "# Inizializzazione del server\n",
    "server_state = federated_algorithm.initialize()\n",
    "evaluate(server_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f80da-a3be-497c-86eb-f437f8850751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento distribuito del modello\n",
    "for _ in range(15):\n",
    "    server_state = federated_algorithm.next(server_state, federated_train_data)\n",
    "    evaluate(server_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
